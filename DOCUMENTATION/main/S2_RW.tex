\section{Literature Review}

\paragraph{}Interpreting speech signals by making a speech to text translation is an active research area especially in current machine learning/deep learning literature. The speech to text translation of call center recordings is an important and specialized application for speech to text translation. Detecting silence in audio recordings can be a pre-processing step in order to optimize processing speed by not-considering audio parts not having significant information. In this work, such a preprocessing framework for detecting silence parts in an audio signal is considered. It is shown that further statistical analysis on the silence distributions results in detecting interesting audio features which can help in finding audio recordings which do not have actual speech sound but a fax machine tone sequence. This foundation can be directly implemented in call center management software and makes it possible to discriminate between a normal conversation recording and a fax sound recording. [1].

\paragraph{}Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics. [2].

\paragraph{}Speech processing is considered to be one of the most important application area of digital signal processing. Speech recognition and translation systems have consisted into two main systems, the first system represents an ASR system that contains two levels which are level one the feature extraction level As well as, level two the classification technique level using Data Time Wrapping (DTW), Hidden Markov Model (HMM), and Dynamic Bayesian Network (DBN). The second system is the Machine Translation (MT) system that mainly can be achieved by using three approaches which are (A) the statistical-based
approach, (B) rule -approach, and (C) hybrid-based approach. In this study, we made a comparative study between
classification techniques from ASR point of view, as well as, the translation approaches from MT point of view. The recognition rate was used in the ASR level and the error rate was used to evaluate the accuracy of the translated sentences. Furthermore, we classified the sample text audio files into four categories which were news, conversational, scientific phrases, and control categories.
 [3].

\paragraph{}Considerable attention has been paid to acquisition device recognition over the past decade in the forensic community, especially in digital image forensics. In contrast, acquisition device clustering from speech recordings is a new problem that aims to merge the recordings acquired by the same device into a single cluster without having prior information about the recordings and training classifiers in advance. In this paper, we propose a method for mobile phone clustering from speech recordings by using a new feature of deep representation and a spectral clustering algorithm. The new feature is learned by a deep auto-encoder network for representing the intrinsic trace left behind by each phone in the recordings, and spectral clustering is used to merge recordings acquired by the same phone into a single cluster. The impacts of the structures of the deep auto-encoder network on the performance of the new feature are discussed. Different features are compared with one another. The proposed method is compared with others and evaluated under special conditions. The results show that the proposed method is effective under these conditions and the new feature outperforms other features. [4]

\paragraph{}This study presents the development of a voice activity detection (VAD) system tested on call center telephony data obtained from our local site. The concept of bag of audio words (BoAW) combined with a na√Øve Bayes classifier was applied to achieve the task. It was formulated as a binary classification problem with speech as the positive class and silence/background noise as the negative class. All the processing was performed on the Mel-frequency cepstral coefficients (MFCCs) extracted from the audio recordings. The results which are presented as accuracy score and receiver operating characteristics (ROC) indicate an excellent performance of the developed model. The system is to be deployed within our call center to aid data analysis and improve overall efficiency of the center. [5]

\newpage